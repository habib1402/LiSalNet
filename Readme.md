# LiSalNet: Lightweight Saliency Detection Network for RGB-D Images

<div align="center">

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Framework](https://img.shields.io/badge/Framework-PyTorch-orange)](https://pytorch.org/)

</div>

## ğŸ“‹ Overview

**LiSalNet** is an efficient lightweight framework for RGB-D salient object detection that achieves state-of-the-art performance while maintaining exceptional computational efficiency.

## ğŸ“Š Performance and Efficiency

**Evaluation on 6 Benchmark Datasets**: NJU2K, NLPR, STERE, DES, LFSD, and SIP. *More Results are coming soon*


### Additional Visual Insights (*More Visuals are coming soon*)

<div align="center">
  <img src="./performance_lines.png" alt=" Comparisons" width="95%">
</div>


## ğŸš€ Code & Resources

> **Note**: The complete source code will be publicly available after paper acceptance.



### Coming Soon (After Acceptance)
- âœ… **Pre-trained Models**: Will be released on the link [Download Models](link-to-models)
- âœ… **Visual Predictions**: Will be released on the link [Download Results on All Datasets](link-to-predictions)
  - NJU2K Dataset Predictions
  - NLPR Dataset Predictions
  - STERE Dataset Predictions
  - DES Dataset Predictions
  - LFSD Dataset Predictions
  - SIP Dataset Predictions
- ğŸ”œ Complete training code
- ğŸ”œ Inference scripts
- ğŸ”œ Model architecture implementation
- ğŸ”œ Preprocessing utilities
- ğŸ”œ Evaluation metrics
- ğŸ”œ Deployment guidelines

## ğŸ“¦ Installation (Preview)
```bash
# Clone the repository (will be available after acceptance)
git clone https://github.com/username/LiSalNet.git
cd LiSalNet

# Create conda environment
conda create -n lisalnet python=3.8
conda activate lisalnet

# Install dependencies
pip install -r requirements.txt
```

## ğŸ¯ Quick Start (Preview)
```python
# Load pre-trained model
from models.lisalnet import LiSalNet

model = LiSalNet(pretrained=True)
model.eval()

# Inference on RGB-D image pair
saliency_map = model(rgb_image, depth_map)
```
## ğŸ”§ Training (Coming Soon)
```bash
# Training script will be available after acceptance
python train.py --config configs/lisalnet_config.yaml
```

## ğŸ“Š Evaluation (Coming Soon)
```bash
# Evaluation script will be available after acceptance
python evaluate.py --dataset NJU2K --model_path checkpoints/lisalnet_best.pth
```

## ğŸ“ Citation

If you find LiSalNet useful in your research, please consider citing:
```bibtex
@article{lisalnet2025,
  title={LiSalNet: Lightweight Saliency Detection Network for RGB-D Images},
  author={Author Names},
  journal={Journal Name},
  year={}
}
```

## ğŸ“§ Contact

For questions and discussions, please contact:
- **Primary Author**: [habibkhan@ieee.org]
- **Lab**: Computational Imaging & Perception Lab, Gachon University

## ğŸ™ Acknowledgments

This work was supported by [Funding Information]. We thank the authors of the benchmark datasets for making their data publicly available.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**â­ Star this repository if you find it helpful!**

</div>




